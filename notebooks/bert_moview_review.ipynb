{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert.tokenization.bert_tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "import pandas as pd\n",
    "sys.path.append('/Users/keemsunguk/Projects/EssayGrader/')\n",
    "from egrader.data_util import load_dataset, MovieReviewData\n",
    "from egrader.bert_util import create_model\n",
    "from egrader.train import train_movie_review\n",
    "from egrader.predict import predict_movie_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_directory_data_local(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"label\"] = []\n",
    "    for file_path in tqdm(os.listdir(directory), desc=os.path.basename(directory)):\n",
    "        with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"label\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset_local(directory):\n",
    "    pos_df = load_directory_data_local(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data_local(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/keemsunguk/Projects/data/aclImdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd9135415654445b25c5023bf72785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90922909dce44c98a0957a6ba53da400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pos', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f973ee294541493a8ac88e4cb2e2a5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='neg', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbd5ad6c71d46f1927b4e2ba8d3475e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pos', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b823d25f21f4ecc9e39eb1c7cc37417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='neg', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train = load_dataset_local(data_dir+'train')\n",
    "#test = load_dataset_local(data_dir+'test')\n",
    "train = load_dataset(data_dir+'train')\n",
    "test = load_dataset(data_dir+'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = map(lambda df: df.reindex(df[\"sentence\"].str.len().sort_values().index), [train, test])  # Sort by the length of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>This movie is terrible but it has some good ef...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21622</th>\n",
       "      <td>I wouldn't rent this one even on dollar rental...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>Ming The Merciless does a little Bardwork and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23939</th>\n",
       "      <td>You'd better choose Paul Verhoeven's even if y...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15459</th>\n",
       "      <td>Adrian Pasdar is excellent is this film. He ma...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20124</th>\n",
       "      <td>*!!- SPOILERS - !!*&lt;br /&gt;&lt;br /&gt;Before I begin ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>By now you've probably heard a bit about the n...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>Titanic directed by James Cameron presents a f...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>**Attention Spoilers**&lt;br /&gt;&lt;br /&gt;First of all...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16774</th>\n",
       "      <td>Match 1: Tag Team Table Match Bubba Ray and Sp...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence label  polarity\n",
       "4537   This movie is terrible but it has some good ef...     3         0\n",
       "21622  I wouldn't rent this one even on dollar rental...     1         0\n",
       "8033   Ming The Merciless does a little Bardwork and ...     1         0\n",
       "23939  You'd better choose Paul Verhoeven's even if y...     3         0\n",
       "15459  Adrian Pasdar is excellent is this film. He ma...     9         1\n",
       "...                                                  ...   ...       ...\n",
       "20124  *!!- SPOILERS - !!*<br /><br />Before I begin ...    10         1\n",
       "4035   By now you've probably heard a bit about the n...    10         1\n",
       "11832  Titanic directed by James Cameron presents a f...     9         1\n",
       "372    **Attention Spoilers**<br /><br />First of all...     9         1\n",
       "16774  Match 1: Tag Team Table Match Bubba Ray and Sp...     9         1\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_ckpt_dir    = '/Users/keemsunguk/Projects/data/uncased_L-2_H-128_A-2'\n",
    "bert_ckpt_file   = '/Users/keemsunguk/Projects/data/uncased_L-2_H-128_A-2/bert_model.ckpt'\n",
    "bert_config_file = '/Users/keemsunguk/Projects/data/uncased_L-2_H-128_A-2/bert_config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fbf17fae524f8da3f6f781c094b28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pos', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71ab0f1e6524661867521350178d312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='neg', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733cbeab0ea44febaa8373671ffed50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pos', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e43fec92ae04c5eb98601e2ae755fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='neg', max=12500.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe83bd568efb48bfb325cb1416157888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f042ad4143714670bdf5ab58a8f458d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max seq_len 178\n",
      "CPU times: user 13.7 s, sys: 3.55 s, total: 17.2 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
    "data = MovieReviewData(tokenizer, \n",
    "                       sample_size=10*128*2,#5000, \n",
    "                       max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            train_x (2560, 128)\n",
      "train_x_token_types (2560, 128)\n",
      "            train_y (2560,)\n",
      "             test_x (2560, 128)\n",
      "        max_seq_len 128\n"
     ]
    }
   ],
   "source": [
    "print(\"            train_x\", data.train_x.shape)\n",
    "print(\"train_x_token_types\", data.train_x_token_types.shape)\n",
    "print(\"            train_y\", data.train_y.shape)\n",
    "\n",
    "print(\"             test_x\", data.test_x.shape)\n",
    "\n",
    "print(\"        max_seq_len\", data.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert shape (None, 128, 128)\n",
      "Done loading 36 BERT weights from: /Users/keemsunguk/Projects/data/uncased_L-2_H-128_A-2/bert_model.ckpt into <bert.model.BertModelLayer object at 0x13e280890> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 128, 128)          4369152   \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 768)               99072     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1538      \n",
      "=================================================================\n",
      "Total params: 4,469,762\n",
      "Trainable params: 4,469,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adapter_size = None # use None to fine-tune all of BERT\n",
    "model = create_model(data.max_seq_len, bert_config_file, bert_ckpt_file, adapter_size=adapter_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, training need GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 5.000000000000001e-07.\n",
      "Epoch 1/40\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.6948 - acc: 0.5551 - val_loss: 0.6718 - val_acc: 0.5898 - lr: 5.0000e-07\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 2/40\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.6927 - acc: 0.5612 - val_loss: 0.6694 - val_acc: 0.5859 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1.5000000000000002e-06.\n",
      "Epoch 3/40\n",
      "48/48 [==============================] - 22s 448ms/step - loss: 0.6938 - acc: 0.5534 - val_loss: 0.6675 - val_acc: 0.5820 - lr: 1.5000e-06\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 2.0000000000000003e-06.\n",
      "Epoch 4/40\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.7001 - acc: 0.5551 - val_loss: 0.6660 - val_acc: 0.5859 - lr: 2.0000e-06\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 2.5000000000000006e-06.\n",
      "Epoch 5/40\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.6926 - acc: 0.5569 - val_loss: 0.6626 - val_acc: 0.6172 - lr: 2.5000e-06\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 3.0000000000000005e-06.\n",
      "Epoch 6/40\n",
      "48/48 [==============================] - 22s 462ms/step - loss: 0.6912 - acc: 0.5560 - val_loss: 0.6577 - val_acc: 0.6445 - lr: 3.0000e-06\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 3.5000000000000004e-06.\n",
      "Epoch 7/40\n",
      "48/48 [==============================] - 22s 452ms/step - loss: 0.6817 - acc: 0.5768 - val_loss: 0.6531 - val_acc: 0.6562 - lr: 3.5000e-06\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 4.000000000000001e-06.\n",
      "Epoch 8/40\n",
      "48/48 [==============================] - 23s 470ms/step - loss: 0.6864 - acc: 0.5690 - val_loss: 0.6453 - val_acc: 0.6484 - lr: 4.0000e-06\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 4.500000000000001e-06.\n",
      "Epoch 9/40\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.6867 - acc: 0.5703 - val_loss: 0.6436 - val_acc: 0.6562 - lr: 4.5000e-06\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 5.000000000000001e-06.\n",
      "Epoch 10/40\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.6838 - acc: 0.5725 - val_loss: 0.6372 - val_acc: 0.6484 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 5.500000000000001e-06.\n",
      "Epoch 11/40\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.6770 - acc: 0.5911 - val_loss: 0.6324 - val_acc: 0.6562 - lr: 5.5000e-06\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 6.000000000000001e-06.\n",
      "Epoch 12/40\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.6739 - acc: 0.5846 - val_loss: 0.6286 - val_acc: 0.6680 - lr: 6.0000e-06\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 6.500000000000001e-06.\n",
      "Epoch 13/40\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.6742 - acc: 0.5933 - val_loss: 0.6248 - val_acc: 0.6602 - lr: 6.5000e-06\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.000000000000001e-06.\n",
      "Epoch 14/40\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.6622 - acc: 0.6185 - val_loss: 0.6182 - val_acc: 0.6797 - lr: 7.0000e-06\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.500000000000001e-06.\n",
      "Epoch 15/40\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.6616 - acc: 0.5964 - val_loss: 0.6129 - val_acc: 0.6836 - lr: 7.5000e-06\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 8.000000000000001e-06.\n",
      "Epoch 16/40\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.6528 - acc: 0.6150 - val_loss: 0.6083 - val_acc: 0.6875 - lr: 8.0000e-06\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 8.500000000000002e-06.\n",
      "Epoch 17/40\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.6537 - acc: 0.6176 - val_loss: 0.6037 - val_acc: 0.6797 - lr: 8.5000e-06\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 9.000000000000002e-06.\n",
      "Epoch 18/40\n",
      "48/48 [==============================] - 22s 448ms/step - loss: 0.6352 - acc: 0.6411 - val_loss: 0.5953 - val_acc: 0.6914 - lr: 9.0000e-06\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 9.500000000000002e-06.\n",
      "Epoch 19/40\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.6285 - acc: 0.6541 - val_loss: 0.5866 - val_acc: 0.6992 - lr: 9.5000e-06\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.0000000000000003e-05.\n",
      "Epoch 20/40\n",
      "48/48 [==============================] - 21s 448ms/step - loss: 0.6285 - acc: 0.6584 - val_loss: 0.5780 - val_acc: 0.7070 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 8.030857221391514e-06.\n",
      "Epoch 21/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.6135 - acc: 0.6597 - val_loss: 0.5666 - val_acc: 0.7266 - lr: 8.0309e-06\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 6.449466771037623e-06.\n",
      "Epoch 22/40\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.6062 - acc: 0.6827 - val_loss: 0.5642 - val_acc: 0.7305 - lr: 6.4495e-06\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 5.1794746792312115e-06.\n",
      "Epoch 23/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5907 - acc: 0.7105 - val_loss: 0.5579 - val_acc: 0.7344 - lr: 5.1795e-06\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 4.159562163071847e-06.\n",
      "Epoch 24/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5845 - acc: 0.7049 - val_loss: 0.5530 - val_acc: 0.7344 - lr: 4.1596e-06\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 3.3404849835132447e-06.\n",
      "Epoch 25/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5836 - acc: 0.7118 - val_loss: 0.5497 - val_acc: 0.7422 - lr: 3.3405e-06\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 2.682695795279726e-06.\n",
      "Epoch 26/40\n",
      "48/48 [==============================] - 21s 448ms/step - loss: 0.5777 - acc: 0.7183 - val_loss: 0.5465 - val_acc: 0.7539 - lr: 2.6827e-06\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 2.1544346900318835e-06.\n",
      "Epoch 27/40\n",
      "48/48 [==============================] - 22s 448ms/step - loss: 0.5781 - acc: 0.7157 - val_loss: 0.5455 - val_acc: 0.7500 - lr: 2.1544e-06\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.730195738845894e-06.\n",
      "Epoch 28/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5733 - acc: 0.7227 - val_loss: 0.5445 - val_acc: 0.7461 - lr: 1.7302e-06\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.3894954943731372e-06.\n",
      "Epoch 29/40\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.5651 - acc: 0.7387 - val_loss: 0.5431 - val_acc: 0.7461 - lr: 1.3895e-06\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.1158839925077483e-06.\n",
      "Epoch 30/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5700 - acc: 0.7331 - val_loss: 0.5423 - val_acc: 0.7461 - lr: 1.1159e-06\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 8.961505019466045e-07.\n",
      "Epoch 31/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5719 - acc: 0.7244 - val_loss: 0.5419 - val_acc: 0.7500 - lr: 8.9615e-07\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 7.196856730011519e-07.\n",
      "Epoch 32/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5785 - acc: 0.7183 - val_loss: 0.5414 - val_acc: 0.7461 - lr: 7.1969e-07\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 5.779692884153312e-07.\n",
      "Epoch 33/40\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.5719 - acc: 0.7309 - val_loss: 0.5411 - val_acc: 0.7461 - lr: 5.7797e-07\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 4.641588833612778e-07.\n",
      "Epoch 34/40\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.5722 - acc: 0.7240 - val_loss: 0.5411 - val_acc: 0.7500 - lr: 4.6416e-07\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 3.7275937203149386e-07.\n",
      "Epoch 35/40\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.5723 - acc: 0.7244 - val_loss: 0.5408 - val_acc: 0.7500 - lr: 3.7276e-07\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.9935772947204884e-07.\n",
      "Epoch 36/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5612 - acc: 0.7348 - val_loss: 0.5406 - val_acc: 0.7539 - lr: 2.9936e-07\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 2.404099183509972e-07.\n",
      "Epoch 37/40\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.5632 - acc: 0.7257 - val_loss: 0.5405 - val_acc: 0.7539 - lr: 2.4041e-07\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.930697728883249e-07.\n",
      "Epoch 38/40\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.5639 - acc: 0.7374 - val_loss: 0.5403 - val_acc: 0.7539 - lr: 1.9307e-07\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.5505157798326237e-07.\n",
      "Epoch 39/40\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.5656 - acc: 0.7326 - val_loss: 0.5402 - val_acc: 0.7539 - lr: 1.5505e-07\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 1.2451970847350323e-07.\n",
      "Epoch 40/40\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.5616 - acc: 0.7279 - val_loss: 0.5401 - val_acc: 0.7539 - lr: 1.2452e-07\n"
     ]
    }
   ],
   "source": [
    "model = train_movie_review(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 8s 106ms/step - loss: 0.5125 - acc: 0.7898\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.5561 - acc: 0.7418\n",
      "train acc 0.789843738079071\n",
      " test acc 0.7417968511581421\n",
      "CPU times: user 56.1 s, sys: 24.4 s, total: 1min 20s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_, train_acc = model.evaluate(data.train_x, data.train_y)\n",
    "_, test_acc = model.evaluate(data.test_x, data.test_y)\n",
    "\n",
    "print(\"train acc\", train_acc)\n",
    "print(\" test acc\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_token_ids (4, 128)\n",
      " text: That movie was absolutely awful\n",
      "  res: negative\n",
      " text: The acting was a bit lacking\n",
      "  res: negative\n",
      " text: The film was creative and surprising\n",
      "  res: positive\n",
      " text: Absolutely fantastic!\n",
      "  res: positive\n"
     ]
    }
   ],
   "source": [
    "pred_sentences = [\n",
    "  \"That movie was absolutely awful\",\n",
    "  \"The acting was a bit lacking\",\n",
    "  \"The film was creative and surprising\",\n",
    "  \"Absolutely fantastic!\"\n",
    "]\n",
    "\n",
    "res = predict_movie_review(model, data, bert_ckpt_dir, pred_sentences)\n",
    "for text, sentiment in zip(pred_sentences, res):\n",
    "    print(\" text:\", text)\n",
    "    print(\"  res:\", [\"negative\",\"positive\"][sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base37",
   "language": "python",
   "name": "base37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
