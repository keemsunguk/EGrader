{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"sk-MivlbsEiNQp7A1K0tYXIs2k2RVYbMQoBdkoCw8W6\"\n",
    "response = openai.Completion.create(engine=\"davinci\", prompt=\"Next year, you will be\", max_tokens=20, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-gofS4n1fFuGAeBEcvcmfL3op at 0x7fadbad01d70> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" able to buy a new car at a price of $20,000.\\n\\nThe following year\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1599539023,\n",
       "  \"id\": \"cmpl-gofS4n1fFuGAeBEcvcmfL3op\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_api(data, prompt, context=None, engine='davinci', max_tokens=5, temperature=0.4, logprobs=5, n:int=1, top_p:float=1):\n",
    "    if context:\n",
    "        prompt = context+'\\n\\n'+data+'\\n\\n'+prompt\n",
    "\n",
    "    response = openai.Completion.create(engine=engine, prompt=prompt, max_tokens=max_tokens, temperature=temperature, logprobs=logprobs, n=n, top_p=top_p)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "When a sentence was given as a prompt, we expect if the prompt is a Claim, Warrant, Thesis or None.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_class = '''\n",
    "S: First, aggressively counter misinformation about mail voting, which continues to be spread not just by President Trump, but also by top members of his administration. \n",
    "C: Claim\n",
    "\n",
    "S: On Tuesday, Attorney General William Barr testified in Congress that he believed mail voting on a large scale presented a “high risk” for massive voter fraud.\n",
    "C: Warrant\n",
    "\n",
    "S: As Mr Barr well knows, voter fraud is rare and is virtually nonexistent in the states where most or all voters cast their ballots by mail. \n",
    "C: Warrant\n",
    "\n",
    "S: The author assumes that the current decline in fish populations in Tria’s waters is caused by overfishing, which resulted from the absence of banning fishing.\n",
    "C: Claim\n",
    "\n",
    "S: He was very smart and strove to pass the exam, only to fail.\n",
    "C: Warrant\n",
    "'''\n",
    "sent_class = '''\n",
    "S: Then such doctors would be miserable everyday due to inconsistent interests.\n",
    "C: Warrant\n",
    "\n",
    "S: However, in my opinion, I think that working for a big company is more beneficial for me in the light of big network and various amenities.\n",
    "C: Claim\n",
    "\n",
    "S: Between the two, I prefer learning about life through personal experience to taking advices from other people because no matter how much I know about life, the knowledge would be useless if I do not truly understand the lessons about life.\n",
    "C: Thesis\n",
    "\n",
    "S; However, children in the present know why they have to conserve the environment.\n",
    "C: Claim\n",
    "\n",
    "S: The girl came from a big city and the boy grew up in the countryside.\n",
    "C: Warrant\n",
    "\n",
    "S: In 2016, nearly one in four voters cast their ballots by mail.\n",
    "C: Warrant\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''S: Harmful effects of smoke are already well established, and therefore less smoke fairly contributes to health improvements of people.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gpt3_api(sent_class, prompt, context=context, max_tokens=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-P3NfhJDe5ig1VYIV1PyxPa6t at 0x7fadbad26e90> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": {\n",
       "        \"text_offset\": [\n",
       "          996,\n",
       "          997,\n",
       "          998,\n",
       "          999,\n",
       "          1005\n",
       "        ],\n",
       "        \"token_logprobs\": [\n",
       "          -0.096491046,\n",
       "          -0.005256417,\n",
       "          -0.0039194934,\n",
       "          -1.1175544,\n",
       "          -0.25950655\n",
       "        ],\n",
       "        \"tokens\": [\n",
       "          \"\\n\",\n",
       "          \"C\",\n",
       "          \":\",\n",
       "          \" Claim\",\n",
       "          \"\\n\"\n",
       "        ],\n",
       "        \"top_logprobs\": [\n",
       "          {\n",
       "            \"\\n\": -0.096491046,\n",
       "            \"\\n\\n\": -4.306959,\n",
       "            \" \": -3.4181154,\n",
       "            \" C\": -4.361067,\n",
       "            \"C\": -4.07823\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -6.2231746,\n",
       "            \"B\": -9.096732,\n",
       "            \"C\": -0.005256417,\n",
       "            \"D\": -8.887246,\n",
       "            \"S\": -6.7513876\n",
       "          },\n",
       "          {\n",
       "            \" :\": -7.37882,\n",
       "            \".\": -7.303972,\n",
       "            \"1\": -8.052206,\n",
       "            \":\": -0.0039194934,\n",
       "            \";\": -7.1418204\n",
       "          },\n",
       "          {\n",
       "            \" Claim\": -1.1175544,\n",
       "            \" None\": -3.3432548,\n",
       "            \" The\": -1.1625259,\n",
       "            \" Warrant\": -1.287007,\n",
       "            \"The\": -5.7905045\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -0.25950655,\n",
       "            \"\\n\\n\": -1.6348156,\n",
       "            \" \": -5.0594635,\n",
       "            \" (\": -4.990608,\n",
       "            \".\": -5.407223\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"text\": \"\\nC: Claim\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1599539051,\n",
       "  \"id\": \"cmpl-P3NfhJDe5ig1VYIV1PyxPa6t\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject at 0x7fdf1a7727d0> JSON: {\n",
       "   \"finish_reason\": \"length\",\n",
       "   \"index\": 0,\n",
       "   \"logprobs\": {\n",
       "     \"text_offset\": [\n",
       "       996,\n",
       "       997,\n",
       "       998,\n",
       "       999,\n",
       "       1003\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -0.093081474,\n",
       "       -0.005508825,\n",
       "       -0.0038891581,\n",
       "       -1.1498631,\n",
       "       -0.0016095614\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \"\\n\",\n",
       "       \"C\",\n",
       "       \":\",\n",
       "       \" The\",\n",
       "       \"sis\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \"\\n\": -0.093081474,\n",
       "         \"\\n\\n\": -4.4738607,\n",
       "         \" \": -3.42615,\n",
       "         \" C\": -4.3074784,\n",
       "         \"C\": -4.152648\n",
       "       },\n",
       "       {\n",
       "         \"\\n\": -6.2283363,\n",
       "         \"B\": -9.010191,\n",
       "         \"C\": -0.005508825,\n",
       "         \"D\": -8.881363,\n",
       "         \"S\": -6.6500435\n",
       "       },\n",
       "       {\n",
       "         \" :\": -7.419481,\n",
       "         \".\": -7.2403083,\n",
       "         \"1\": -8.115591,\n",
       "         \":\": -0.0038891581,\n",
       "         \";\": -7.286188\n",
       "       },\n",
       "       {\n",
       "         \" Claim\": -1.1358594,\n",
       "         \" None\": -3.3678539,\n",
       "         \" The\": -1.1498631,\n",
       "         \" Warrant\": -1.2777853,\n",
       "         \"The\": -5.7857003\n",
       "       },\n",
       "       {\n",
       "         \" claim\": -8.37596,\n",
       "         \" thesis\": -8.34988,\n",
       "         \" warrant\": -9.590762,\n",
       "         \"ses\": -8.050902,\n",
       "         \"sis\": -0.0016095614\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   \"text\": \"\\nC: Thesis\"\n",
       " }]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d for d in a['choices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-149-c76ad4a12e70>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-149-c76ad4a12e70>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for choice in a['choices']\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "fn = None\n",
    "parsed_a = [d['text'], round(prob, 4) if fn is None else (fn(d['text']), round(prob,4), d['text']) \\\n",
    "            for choice in a['choices']\n",
    "            for d in [choice.to_dict()]\n",
    "            for probs in [d['logprobs']['token_logprobs']]\n",
    "            for prob in [math.exp(sum(probs)/len(probs))]\n",
    "           ]\n",
    "parsed_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "prompts.append('''S: Harmful effects of smoke are already well established, and therefore less smoke fairly contributes to health improvements of people.''')\n",
    "prompts.append('''S: Second, public officials must educate voters.''')\n",
    "prompts.append('''S: The extreme case well illustrates that a politician is willing to control information to his own benefit.\\n''')\n",
    "prompts.append('''S: However, as he learns about the reality that his mother in fact did not die, but actually had ran away with another man, he at first gets in shock.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: Claim\n",
      "\n",
      "\n",
      "C: Thesis\n",
      "C: Thesis\n",
      "\n",
      "\n",
      "C: Claim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    a = gpt3_api(sent_class, prompt, context=context, max_tokens=5, temperature=0.4)\n",
    "    print(a['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base37",
   "language": "python",
   "name": "base37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
